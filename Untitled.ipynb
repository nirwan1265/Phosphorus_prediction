{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "896c6bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb80b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('data/filtered_data/P_Bray_mcdowell2023_predictors_he2022_global.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b124bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['x','y','ID', 'EROIDX', 'TCEQ', 'CACO3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af73f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['BEDROCK', 'SOIL.TYPE', 'DEPTH', 'NPP', 'BIOMES']\n",
    "data = pd.get_dummies(data, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b5fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into predictors and target\n",
    "X = data.drop(columns=['p_avg']).values\n",
    "y = data['p_avg'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1958bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize continuous variables\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9952aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c313ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752a7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformer model\n",
    "class TabularTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nhead, num_layers, dropout=0.5):\n",
    "        super(TabularTransformer, self).__init__()\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c047b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "nhead = 2\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "add61860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model = TabularTransformer(input_dim, output_dim, nhead, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c7c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9ab364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1103.0540\n",
      "Epoch [2/10], Loss: 885.4127\n",
      "Epoch [3/10], Loss: 828.2811\n",
      "Epoch [4/10], Loss: 813.1437\n",
      "Epoch [5/10], Loss: 805.4667\n",
      "Epoch [6/10], Loss: 798.2857\n",
      "Epoch [7/10], Loss: 790.2875\n",
      "Epoch [8/10], Loss: 781.7697\n",
      "Epoch [9/10], Loss: 773.4894\n",
      "Epoch [10/10], Loss: 767.5089\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31389a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 819.3730\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(X_val_tensor)\n",
    "    val_loss = criterion(val_outputs, y_val_tensor)\n",
    "print(f\"Validation Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f883180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 17.3107\n",
      "Root Mean Squared Error (RMSE): 28.6247\n",
      "R-squared Value: -0.0905\n"
     ]
    }
   ],
   "source": [
    "# Compute additional evaluation metrics\n",
    "mae = torch.mean(torch.abs(val_outputs - y_val_tensor))\n",
    "rmse = torch.sqrt(val_loss)\n",
    "r2_score = 1 - torch.sum((y_val_tensor - val_outputs) ** 2) / torch.sum((y_val_tensor - torch.mean(y_val_tensor)) ** 2)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae.item():.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse.item():.4f}\")\n",
    "print(f\"R-squared Value: {r2_score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4cc88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_selection",
   "language": "python",
   "name": "feature_selection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
